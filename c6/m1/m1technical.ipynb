{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb31ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (1.7.1)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (3.10.0)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/ml-env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "Using cached matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Installing collected packages: numpy, scikit-learn, matplotlib\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[2K  Attempting uninstall: scikit-learn━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.132m0/3\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.1:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.1━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: matplotlibm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.0━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.0:[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [matplotlib]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.0\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [matplotlib]3\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed matplotlib-3.10.6 numpy-2.2.6 scikit-learn-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow scikit-learn numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62baf234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ce527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (20640, 8)\n",
      "Target shape: (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Load the California Housing dataset\n",
    "cal_data = fetch_california_housing()\n",
    "X = cal_data.data\n",
    "y = cal_data.target\n",
    "\n",
    "print(\"Data shape:\", X.shape)        # Should be (20640, 8)\n",
    "print(\"Target shape:\", y.shape)      # Should be (20640,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fcb08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (13209, 8)\n",
      "Validation data shape: (3303, 8)\n",
      "Test data shape: (4128, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test first\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Further split train data into train and validation\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training data shape:\", X_train_final.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f9fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature means: [ 3.86893364e+00  2.85672647e+01  5.42040408e+00  1.09433536e+00\n",
      "  1.42691650e+03  3.02944025e+00  3.56468476e+01 -1.19583303e+02]\n",
      "Feature variances: [3.57143560e+00 1.58482738e+02 4.48993988e+00 1.45205080e-01\n",
      " 1.29315681e+06 4.70353691e+01 4.55294423e+00 4.02078197e+00]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_final)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_final)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature means:\", scaler.mean_)\n",
    "print(\"Feature variances:\", scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f7c025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - loss: 0.8175 - mae: 0.6163 - mse: 0.8175 - val_loss: 0.5284 - val_mae: 0.4908 - val_mse: 0.5284\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.3952 - mae: 0.4456 - mse: 0.3952 - val_loss: 0.3943 - val_mae: 0.4558 - val_mse: 0.3943\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.3651 - mae: 0.4279 - mse: 0.3651 - val_loss: 0.5870 - val_mae: 0.4451 - val_mse: 0.5870\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 0.3638 - mae: 0.4168 - mse: 0.3638 - val_loss: 0.5086 - val_mae: 0.4337 - val_mse: 0.5086\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.3342 - mae: 0.4058 - mse: 0.3342 - val_loss: 0.3618 - val_mae: 0.4156 - val_mse: 0.3618\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.3277 - mae: 0.3983 - mse: 0.3277 - val_loss: 0.4263 - val_mae: 0.4260 - val_mse: 0.4263\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.3261 - mae: 0.3943 - mse: 0.3261 - val_loss: 0.3455 - val_mae: 0.4039 - val_mse: 0.3455\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.3089 - mae: 0.3880 - mse: 0.3089 - val_loss: 0.3515 - val_mae: 0.4044 - val_mse: 0.3515\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.3080 - mae: 0.3858 - mse: 0.3080 - val_loss: 0.3926 - val_mae: 0.4142 - val_mse: 0.3926\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 0.3032 - mae: 0.3842 - mse: 0.3032 - val_loss: 0.3348 - val_mae: 0.4032 - val_mse: 0.3348\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.2959 - mae: 0.3783 - mse: 0.2959 - val_loss: 0.3417 - val_mae: 0.3897 - val_mse: 0.3417\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.3034 - mae: 0.3803 - mse: 0.3034 - val_loss: 0.3817 - val_mae: 0.3993 - val_mse: 0.3817\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.2950 - mae: 0.3772 - mse: 0.2950 - val_loss: 0.3309 - val_mae: 0.4042 - val_mse: 0.3309\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2924 - mae: 0.3732 - mse: 0.2924 - val_loss: 0.3698 - val_mae: 0.4006 - val_mse: 0.3698\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.2881 - mae: 0.3705 - mse: 0.2881 - val_loss: 0.3219 - val_mae: 0.3901 - val_mse: 0.3219\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.2874 - mae: 0.3716 - mse: 0.2874 - val_loss: 0.3401 - val_mae: 0.3959 - val_mse: 0.3401\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2851 - mae: 0.3702 - mse: 0.2851 - val_loss: 0.3186 - val_mae: 0.3945 - val_mse: 0.3186\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2839 - mae: 0.3680 - mse: 0.2839 - val_loss: 0.3326 - val_mae: 0.4024 - val_mse: 0.3326\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2875 - mae: 0.3688 - mse: 0.2875 - val_loss: 0.3129 - val_mae: 0.3811 - val_mse: 0.3129\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2843 - mae: 0.3657 - mse: 0.2843 - val_loss: 0.3469 - val_mae: 0.3820 - val_mse: 0.3469\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2802 - mae: 0.3653 - mse: 0.2802 - val_loss: 0.3336 - val_mae: 0.3953 - val_mse: 0.3336\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2752 - mae: 0.3621 - mse: 0.2752 - val_loss: 0.3242 - val_mae: 0.4046 - val_mse: 0.3242\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2725 - mae: 0.3603 - mse: 0.2725 - val_loss: 0.2946 - val_mae: 0.3751 - val_mse: 0.2946\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2713 - mae: 0.3583 - mse: 0.2713 - val_loss: 0.3001 - val_mae: 0.3722 - val_mse: 0.3001\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2737 - mae: 0.3610 - mse: 0.2737 - val_loss: 0.3038 - val_mae: 0.3742 - val_mse: 0.3038\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2714 - mae: 0.3587 - mse: 0.2714 - val_loss: 0.3046 - val_mae: 0.3819 - val_mse: 0.3046\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.2714 - mae: 0.3592 - mse: 0.2714 - val_loss: 0.2968 - val_mae: 0.3813 - val_mse: 0.2968\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 0.2649 - mae: 0.3538 - mse: 0.2649 - val_loss: 0.3117 - val_mae: 0.3755 - val_mse: 0.3117\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.2643 - mae: 0.3540 - mse: 0.2643 - val_loss: 0.2972 - val_mae: 0.3697 - val_mse: 0.2972\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2648 - mae: 0.3551 - mse: 0.2648 - val_loss: 0.3215 - val_mae: 0.4007 - val_mse: 0.3215\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2622 - mae: 0.3519 - mse: 0.2622 - val_loss: 0.3088 - val_mae: 0.3755 - val_mse: 0.3088\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.2611 - mae: 0.3523 - mse: 0.2611 - val_loss: 0.2962 - val_mae: 0.3768 - val_mse: 0.2962\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2610 - mae: 0.3523 - mse: 0.2610 - val_loss: 0.3118 - val_mae: 0.3740 - val_mse: 0.3118\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2598 - mae: 0.3505 - mse: 0.2598 - val_loss: 0.2857 - val_mae: 0.3656 - val_mse: 0.2857\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.2608 - mae: 0.3516 - mse: 0.2608 - val_loss: 0.3336 - val_mae: 0.3700 - val_mse: 0.3336\n",
      "Epoch 36/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.2619 - mae: 0.3509 - mse: 0.2619 - val_loss: 0.3114 - val_mae: 0.3797 - val_mse: 0.3114\n",
      "Epoch 37/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2619 - mae: 0.3512 - mse: 0.2619 - val_loss: 0.3053 - val_mae: 0.3729 - val_mse: 0.3053\n",
      "Epoch 38/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2578 - mae: 0.3481 - mse: 0.2578 - val_loss: 0.3093 - val_mae: 0.3742 - val_mse: 0.3093\n",
      "Epoch 39/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.2561 - mae: 0.3481 - mse: 0.2561 - val_loss: 0.3158 - val_mae: 0.3816 - val_mse: 0.3158\n",
      "Epoch 40/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.2532 - mae: 0.3463 - mse: 0.2532 - val_loss: 0.3110 - val_mae: 0.3788 - val_mse: 0.3110\n",
      "Epoch 41/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2552 - mae: 0.3479 - mse: 0.2552 - val_loss: 0.2826 - val_mae: 0.3611 - val_mse: 0.2826\n",
      "Epoch 42/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.2527 - mae: 0.3449 - mse: 0.2527 - val_loss: 0.3024 - val_mae: 0.3669 - val_mse: 0.3024\n",
      "Epoch 43/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.2506 - mae: 0.3435 - mse: 0.2506 - val_loss: 0.2931 - val_mae: 0.3727 - val_mse: 0.2931\n",
      "Epoch 44/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2536 - mae: 0.3461 - mse: 0.2536 - val_loss: 0.3215 - val_mae: 0.3738 - val_mse: 0.3215\n",
      "Epoch 45/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2499 - mae: 0.3414 - mse: 0.2499 - val_loss: 0.2938 - val_mae: 0.3646 - val_mse: 0.2938\n",
      "Epoch 46/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2494 - mae: 0.3438 - mse: 0.2494 - val_loss: 0.2872 - val_mae: 0.3740 - val_mse: 0.2872\n",
      "Epoch 47/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2473 - mae: 0.3417 - mse: 0.2473 - val_loss: 0.3092 - val_mae: 0.3695 - val_mse: 0.3092\n",
      "Epoch 48/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2468 - mae: 0.3408 - mse: 0.2468 - val_loss: 0.3037 - val_mae: 0.3763 - val_mse: 0.3037\n",
      "Epoch 49/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.2443 - mae: 0.3383 - mse: 0.2443 - val_loss: 0.3001 - val_mae: 0.3693 - val_mse: 0.3001\n",
      "Epoch 50/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2460 - mae: 0.3392 - mse: 0.2460 - val_loss: 0.3017 - val_mae: 0.3772 - val_mse: 0.3017\n",
      "Epoch 51/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2456 - mae: 0.3386 - mse: 0.2456 - val_loss: 0.2983 - val_mae: 0.3835 - val_mse: 0.2983\n",
      "Epoch 52/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2429 - mae: 0.3374 - mse: 0.2429 - val_loss: 0.3072 - val_mae: 0.3611 - val_mse: 0.3072\n",
      "Epoch 53/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2424 - mae: 0.3371 - mse: 0.2424 - val_loss: 0.3242 - val_mae: 0.3793 - val_mse: 0.3242\n",
      "Epoch 54/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2402 - mae: 0.3368 - mse: 0.2402 - val_loss: 0.2938 - val_mae: 0.3574 - val_mse: 0.2938\n",
      "Epoch 55/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2386 - mae: 0.3351 - mse: 0.2386 - val_loss: 0.2892 - val_mae: 0.3642 - val_mse: 0.2892\n",
      "Epoch 56/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.2393 - mae: 0.3359 - mse: 0.2393 - val_loss: 0.3031 - val_mae: 0.3592 - val_mse: 0.3031\n",
      "Epoch 57/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2384 - mae: 0.3346 - mse: 0.2384 - val_loss: 0.2850 - val_mae: 0.3592 - val_mse: 0.2850\n",
      "Epoch 58/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2383 - mae: 0.3343 - mse: 0.2383 - val_loss: 0.2943 - val_mae: 0.3893 - val_mse: 0.2943\n",
      "Epoch 59/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2370 - mae: 0.3346 - mse: 0.2370 - val_loss: 0.2786 - val_mae: 0.3579 - val_mse: 0.2786\n",
      "Epoch 60/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2367 - mae: 0.3334 - mse: 0.2367 - val_loss: 0.2753 - val_mae: 0.3603 - val_mse: 0.2753\n",
      "Epoch 61/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2342 - mae: 0.3318 - mse: 0.2342 - val_loss: 0.2909 - val_mae: 0.3694 - val_mse: 0.2909\n",
      "Epoch 62/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2362 - mae: 0.3334 - mse: 0.2362 - val_loss: 0.2924 - val_mae: 0.3554 - val_mse: 0.2924\n",
      "Epoch 63/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2352 - mae: 0.3321 - mse: 0.2352 - val_loss: 0.3569 - val_mae: 0.3583 - val_mse: 0.3569\n",
      "Epoch 64/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2342 - mae: 0.3305 - mse: 0.2342 - val_loss: 0.3026 - val_mae: 0.3818 - val_mse: 0.3026\n",
      "Epoch 65/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2313 - mae: 0.3312 - mse: 0.2313 - val_loss: 0.3116 - val_mae: 0.3569 - val_mse: 0.3116\n",
      "Epoch 66/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2314 - mae: 0.3290 - mse: 0.2314 - val_loss: 0.2795 - val_mae: 0.3642 - val_mse: 0.2795\n",
      "Epoch 67/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2316 - mae: 0.3290 - mse: 0.2316 - val_loss: 0.3186 - val_mae: 0.3603 - val_mse: 0.3186\n",
      "Epoch 68/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.2362 - mae: 0.3316 - mse: 0.2362 - val_loss: 0.2805 - val_mae: 0.3566 - val_mse: 0.2805\n",
      "Epoch 69/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2287 - mae: 0.3274 - mse: 0.2287 - val_loss: 0.2778 - val_mae: 0.3557 - val_mse: 0.2778\n",
      "Epoch 70/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.2268 - mae: 0.3265 - mse: 0.2268 - val_loss: 0.3000 - val_mae: 0.3762 - val_mse: 0.3000\n",
      "Epoch 71/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2268 - mae: 0.3268 - mse: 0.2268 - val_loss: 0.2718 - val_mae: 0.3572 - val_mse: 0.2718\n",
      "Epoch 72/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2267 - mae: 0.3264 - mse: 0.2267 - val_loss: 0.2834 - val_mae: 0.3642 - val_mse: 0.2834\n",
      "Epoch 73/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.2252 - mae: 0.3251 - mse: 0.2252 - val_loss: 0.2883 - val_mae: 0.3671 - val_mse: 0.2883\n",
      "Epoch 74/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2264 - mae: 0.3262 - mse: 0.2264 - val_loss: 0.2764 - val_mae: 0.3594 - val_mse: 0.2764\n",
      "Epoch 75/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2281 - mae: 0.3278 - mse: 0.2281 - val_loss: 0.2876 - val_mae: 0.3689 - val_mse: 0.2876\n",
      "Epoch 76/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2245 - mae: 0.3254 - mse: 0.2245 - val_loss: 0.2797 - val_mae: 0.3588 - val_mse: 0.2797\n",
      "Epoch 77/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.2246 - mae: 0.3261 - mse: 0.2246 - val_loss: 0.2814 - val_mae: 0.3546 - val_mse: 0.2814\n",
      "Epoch 78/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.2221 - mae: 0.3228 - mse: 0.2221 - val_loss: 0.2829 - val_mae: 0.3557 - val_mse: 0.2829\n",
      "Epoch 79/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2233 - mae: 0.3248 - mse: 0.2233 - val_loss: 0.2936 - val_mae: 0.3586 - val_mse: 0.2936\n",
      "Epoch 80/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 0.2223 - mae: 0.3228 - mse: 0.2223 - val_loss: 0.3043 - val_mae: 0.3706 - val_mse: 0.3043\n",
      "Epoch 81/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.2204 - mae: 0.3227 - mse: 0.2204 - val_loss: 0.2744 - val_mae: 0.3612 - val_mse: 0.2744\n",
      "Epoch 82/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2225 - mae: 0.3235 - mse: 0.2225 - val_loss: 0.2816 - val_mae: 0.3600 - val_mse: 0.2816\n",
      "Epoch 83/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2220 - mae: 0.3227 - mse: 0.2220 - val_loss: 0.2795 - val_mae: 0.3561 - val_mse: 0.2795\n",
      "Epoch 84/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2184 - mae: 0.3210 - mse: 0.2184 - val_loss: 0.2966 - val_mae: 0.3815 - val_mse: 0.2966\n",
      "Epoch 85/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2195 - mae: 0.3210 - mse: 0.2195 - val_loss: 0.2919 - val_mae: 0.3699 - val_mse: 0.2919\n",
      "Epoch 86/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.2189 - mae: 0.3217 - mse: 0.2189 - val_loss: 0.3023 - val_mae: 0.3581 - val_mse: 0.3023\n",
      "Epoch 87/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.2182 - mae: 0.3211 - mse: 0.2182 - val_loss: 0.2864 - val_mae: 0.3567 - val_mse: 0.2864\n",
      "Epoch 88/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2177 - mae: 0.3197 - mse: 0.2177 - val_loss: 0.2772 - val_mae: 0.3575 - val_mse: 0.2772\n",
      "Epoch 89/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2163 - mae: 0.3198 - mse: 0.2163 - val_loss: 0.2792 - val_mae: 0.3547 - val_mse: 0.2792\n",
      "Epoch 90/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2165 - mae: 0.3183 - mse: 0.2165 - val_loss: 0.2939 - val_mae: 0.3595 - val_mse: 0.2939\n",
      "Epoch 91/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2176 - mae: 0.3208 - mse: 0.2176 - val_loss: 0.3815 - val_mae: 0.3706 - val_mse: 0.3815\n",
      "Epoch 92/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2205 - mae: 0.3195 - mse: 0.2205 - val_loss: 0.2872 - val_mae: 0.3728 - val_mse: 0.2872\n",
      "Epoch 93/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.2137 - mae: 0.3179 - mse: 0.2137 - val_loss: 0.2728 - val_mae: 0.3590 - val_mse: 0.2728\n",
      "Epoch 94/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2141 - mae: 0.3187 - mse: 0.2141 - val_loss: 0.2730 - val_mae: 0.3515 - val_mse: 0.2730\n",
      "Epoch 95/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2128 - mae: 0.3171 - mse: 0.2128 - val_loss: 0.2720 - val_mae: 0.3511 - val_mse: 0.2720\n",
      "Epoch 96/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.2127 - mae: 0.3163 - mse: 0.2127 - val_loss: 0.2817 - val_mae: 0.3550 - val_mse: 0.2817\n",
      "Epoch 97/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2135 - mae: 0.3164 - mse: 0.2135 - val_loss: 0.2949 - val_mae: 0.3584 - val_mse: 0.2949\n",
      "Epoch 98/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2134 - mae: 0.3169 - mse: 0.2134 - val_loss: 0.2746 - val_mae: 0.3587 - val_mse: 0.2746\n",
      "Epoch 99/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2099 - mae: 0.3145 - mse: 0.2099 - val_loss: 0.2883 - val_mae: 0.3699 - val_mse: 0.2883\n",
      "Epoch 100/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2119 - mae: 0.3158 - mse: 0.2119 - val_loss: 0.2739 - val_mae: 0.3585 - val_mse: 0.2739\n"
     ]
    }
   ],
   "source": [
    "baseline_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_baseline = baseline_model.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6b5d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - loss: 0.7165 - mae: 0.6045 - mse: 0.7165 - val_loss: 0.6474 - val_mae: 0.5236 - val_mse: 0.6474\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.4428 - mae: 0.4799 - mse: 0.4428 - val_loss: 0.9916 - val_mae: 0.6114 - val_mse: 0.9916\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.4091 - mae: 0.4610 - mse: 0.4091 - val_loss: 1.5981 - val_mae: 0.4530 - val_mse: 1.5981\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.4036 - mae: 0.4559 - mse: 0.4036 - val_loss: 0.5250 - val_mae: 0.4805 - val_mse: 0.5250\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.3828 - mae: 0.4434 - mse: 0.3828 - val_loss: 0.4708 - val_mae: 0.4537 - val_mse: 0.4708\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 0.3725 - mae: 0.4365 - mse: 0.3725 - val_loss: 0.8507 - val_mae: 0.5797 - val_mse: 0.8507\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3663 - mae: 0.4309 - mse: 0.3663 - val_loss: 0.5376 - val_mae: 0.4642 - val_mse: 0.5376\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3621 - mae: 0.4298 - mse: 0.3621 - val_loss: 1.4213 - val_mae: 0.5201 - val_mse: 1.4213\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.3593 - mae: 0.4265 - mse: 0.3593 - val_loss: 0.3705 - val_mae: 0.4181 - val_mse: 0.3705\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.3633 - mae: 0.4308 - mse: 0.3633 - val_loss: 0.4363 - val_mae: 0.4465 - val_mse: 0.4363\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.3600 - mae: 0.4284 - mse: 0.3600 - val_loss: 0.5960 - val_mae: 0.5043 - val_mse: 0.5960\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.3594 - mae: 0.4262 - mse: 0.3594 - val_loss: 0.6908 - val_mae: 0.5353 - val_mse: 0.6908\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.3512 - mae: 0.4222 - mse: 0.3512 - val_loss: 0.4315 - val_mae: 0.4245 - val_mse: 0.4315\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.3546 - mae: 0.4241 - mse: 0.3546 - val_loss: 0.7343 - val_mae: 0.5515 - val_mse: 0.7343\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3483 - mae: 0.4200 - mse: 0.3483 - val_loss: 1.3884 - val_mae: 0.5518 - val_mse: 1.3884\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.3491 - mae: 0.4179 - mse: 0.3491 - val_loss: 1.0789 - val_mae: 0.4823 - val_mse: 1.0789\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3391 - mae: 0.4152 - mse: 0.3391 - val_loss: 0.8697 - val_mae: 0.5035 - val_mse: 0.8697\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3386 - mae: 0.4129 - mse: 0.3386 - val_loss: 0.7419 - val_mae: 0.4965 - val_mse: 0.7419\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3303 - mae: 0.4069 - mse: 0.3303 - val_loss: 1.1468 - val_mae: 0.4717 - val_mse: 1.1468\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3345 - mae: 0.4117 - mse: 0.3345 - val_loss: 0.9480 - val_mae: 0.5510 - val_mse: 0.9480\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3341 - mae: 0.4112 - mse: 0.3341 - val_loss: 0.8817 - val_mae: 0.4627 - val_mse: 0.8817\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3396 - mae: 0.4133 - mse: 0.3396 - val_loss: 0.8766 - val_mae: 0.5188 - val_mse: 0.8766\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.3239 - mae: 0.4016 - mse: 0.3239 - val_loss: 0.7795 - val_mae: 0.5123 - val_mse: 0.7795\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3295 - mae: 0.4077 - mse: 0.3295 - val_loss: 0.9291 - val_mae: 0.4535 - val_mse: 0.9291\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.3258 - mae: 0.4056 - mse: 0.3258 - val_loss: 1.2019 - val_mae: 0.5833 - val_mse: 1.2019\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.3251 - mae: 0.4054 - mse: 0.3251 - val_loss: 0.5991 - val_mae: 0.4435 - val_mse: 0.5991\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 0.3246 - mae: 0.4043 - mse: 0.3246 - val_loss: 1.3317 - val_mae: 0.5846 - val_mse: 1.3317\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 0.3324 - mae: 0.4087 - mse: 0.3324 - val_loss: 1.0964 - val_mae: 0.5067 - val_mse: 1.0964\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3287 - mae: 0.4065 - mse: 0.3287 - val_loss: 0.5619 - val_mae: 0.4881 - val_mse: 0.5619\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.3271 - mae: 0.4071 - mse: 0.3271 - val_loss: 1.5499 - val_mae: 0.5923 - val_mse: 1.5499\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3196 - mae: 0.4001 - mse: 0.3196 - val_loss: 1.4448 - val_mae: 0.5177 - val_mse: 1.4448\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3207 - mae: 0.3991 - mse: 0.3207 - val_loss: 0.7975 - val_mae: 0.4895 - val_mse: 0.7975\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.3227 - mae: 0.4015 - mse: 0.3227 - val_loss: 1.9180 - val_mae: 0.5971 - val_mse: 1.9180\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3182 - mae: 0.3989 - mse: 0.3182 - val_loss: 0.7233 - val_mae: 0.5234 - val_mse: 0.7233\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3155 - mae: 0.3993 - mse: 0.3155 - val_loss: 0.6152 - val_mae: 0.5064 - val_mse: 0.6152\n",
      "Epoch 36/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3171 - mae: 0.3975 - mse: 0.3171 - val_loss: 0.5833 - val_mae: 0.4430 - val_mse: 0.5833\n",
      "Epoch 37/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.3118 - mae: 0.3937 - mse: 0.3118 - val_loss: 0.6686 - val_mae: 0.4722 - val_mse: 0.6686\n",
      "Epoch 38/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.3212 - mae: 0.3995 - mse: 0.3212 - val_loss: 0.4303 - val_mae: 0.4053 - val_mse: 0.4303\n",
      "Epoch 39/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.3124 - mae: 0.3964 - mse: 0.3124 - val_loss: 1.0461 - val_mae: 0.5776 - val_mse: 1.0461\n",
      "Epoch 40/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.3122 - mae: 0.3928 - mse: 0.3122 - val_loss: 0.7069 - val_mae: 0.5407 - val_mse: 0.7069\n",
      "Epoch 41/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3141 - mae: 0.3975 - mse: 0.3141 - val_loss: 0.8552 - val_mae: 0.5337 - val_mse: 0.8552\n",
      "Epoch 42/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.3128 - mae: 0.3946 - mse: 0.3128 - val_loss: 1.1870 - val_mae: 0.6017 - val_mse: 1.1870\n",
      "Epoch 43/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.3189 - mae: 0.3990 - mse: 0.3189 - val_loss: 0.5717 - val_mae: 0.4837 - val_mse: 0.5717\n",
      "Epoch 44/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 0.3083 - mae: 0.3924 - mse: 0.3083 - val_loss: 0.7008 - val_mae: 0.5531 - val_mse: 0.7008\n",
      "Epoch 45/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.3108 - mae: 0.3956 - mse: 0.3108 - val_loss: 0.7230 - val_mae: 0.5331 - val_mse: 0.7230\n",
      "Epoch 46/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.3079 - mae: 0.3932 - mse: 0.3079 - val_loss: 0.5027 - val_mae: 0.4627 - val_mse: 0.5027\n",
      "Epoch 47/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3095 - mae: 0.3919 - mse: 0.3095 - val_loss: 0.9495 - val_mae: 0.5279 - val_mse: 0.9495\n",
      "Epoch 48/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.3037 - mae: 0.3889 - mse: 0.3037 - val_loss: 0.6152 - val_mae: 0.5012 - val_mse: 0.6152\n",
      "Epoch 49/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.3051 - mae: 0.3906 - mse: 0.3051 - val_loss: 0.6395 - val_mae: 0.5305 - val_mse: 0.6395\n",
      "Epoch 50/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.3019 - mae: 0.3889 - mse: 0.3019 - val_loss: 0.5476 - val_mae: 0.4870 - val_mse: 0.5476\n",
      "Epoch 51/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3001 - mae: 0.3866 - mse: 0.3001 - val_loss: 0.4831 - val_mae: 0.4191 - val_mse: 0.4831\n",
      "Epoch 52/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.3055 - mae: 0.3911 - mse: 0.3055 - val_loss: 0.4815 - val_mae: 0.4420 - val_mse: 0.4815\n",
      "Epoch 53/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.3017 - mae: 0.3892 - mse: 0.3017 - val_loss: 0.5423 - val_mae: 0.4829 - val_mse: 0.5423\n",
      "Epoch 54/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.3059 - mae: 0.3907 - mse: 0.3059 - val_loss: 0.6628 - val_mae: 0.5089 - val_mse: 0.6628\n",
      "Epoch 55/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.3050 - mae: 0.3876 - mse: 0.3050 - val_loss: 0.5752 - val_mae: 0.4912 - val_mse: 0.5752\n",
      "Epoch 56/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.3049 - mae: 0.3902 - mse: 0.3049 - val_loss: 0.5912 - val_mae: 0.5004 - val_mse: 0.5912\n",
      "Epoch 57/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 0.3051 - mae: 0.3894 - mse: 0.3051 - val_loss: 0.4107 - val_mae: 0.4220 - val_mse: 0.4107\n",
      "Epoch 58/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.3076 - mae: 0.3918 - mse: 0.3076 - val_loss: 0.6278 - val_mae: 0.5181 - val_mse: 0.6278\n",
      "Epoch 59/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.3027 - mae: 0.3869 - mse: 0.3027 - val_loss: 0.9116 - val_mae: 0.4950 - val_mse: 0.9116\n",
      "Epoch 60/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.3036 - mae: 0.3903 - mse: 0.3036 - val_loss: 0.4262 - val_mae: 0.4432 - val_mse: 0.4262\n",
      "Epoch 61/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 0.3000 - mae: 0.3860 - mse: 0.3000 - val_loss: 0.3932 - val_mae: 0.4014 - val_mse: 0.3932\n",
      "Epoch 62/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.3011 - mae: 0.3892 - mse: 0.3011 - val_loss: 0.6857 - val_mae: 0.4729 - val_mse: 0.6857\n",
      "Epoch 63/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.2993 - mae: 0.3856 - mse: 0.2993 - val_loss: 0.5975 - val_mae: 0.4773 - val_mse: 0.5975\n",
      "Epoch 64/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.2959 - mae: 0.3844 - mse: 0.2959 - val_loss: 0.4573 - val_mae: 0.4421 - val_mse: 0.4573\n",
      "Epoch 65/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.3029 - mae: 0.3886 - mse: 0.3029 - val_loss: 0.8624 - val_mae: 0.5450 - val_mse: 0.8624\n",
      "Epoch 66/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2925 - mae: 0.3821 - mse: 0.2925 - val_loss: 0.7421 - val_mae: 0.4896 - val_mse: 0.7421\n",
      "Epoch 67/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.3007 - mae: 0.3875 - mse: 0.3007 - val_loss: 0.6422 - val_mae: 0.5406 - val_mse: 0.6422\n",
      "Epoch 68/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.3012 - mae: 0.3877 - mse: 0.3012 - val_loss: 0.7497 - val_mae: 0.5515 - val_mse: 0.7497\n",
      "Epoch 69/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.2991 - mae: 0.3877 - mse: 0.2991 - val_loss: 0.5682 - val_mae: 0.4518 - val_mse: 0.5682\n",
      "Epoch 70/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.3002 - mae: 0.3860 - mse: 0.3002 - val_loss: 0.5457 - val_mae: 0.4706 - val_mse: 0.5457\n",
      "Epoch 71/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.3026 - mae: 0.3901 - mse: 0.3026 - val_loss: 0.5332 - val_mae: 0.4772 - val_mse: 0.5332\n",
      "Epoch 72/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.2916 - mae: 0.3793 - mse: 0.2916 - val_loss: 0.5131 - val_mae: 0.4566 - val_mse: 0.5131\n",
      "Epoch 73/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.2931 - mae: 0.3809 - mse: 0.2931 - val_loss: 0.4238 - val_mae: 0.4283 - val_mse: 0.4238\n",
      "Epoch 74/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2968 - mae: 0.3846 - mse: 0.2968 - val_loss: 0.5785 - val_mae: 0.4301 - val_mse: 0.5785\n",
      "Epoch 75/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 0.2968 - mae: 0.3861 - mse: 0.2968 - val_loss: 0.9030 - val_mae: 0.5861 - val_mse: 0.9030\n",
      "Epoch 76/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.2955 - mae: 0.3837 - mse: 0.2955 - val_loss: 0.4643 - val_mae: 0.4285 - val_mse: 0.4643\n",
      "Epoch 77/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2951 - mae: 0.3828 - mse: 0.2951 - val_loss: 0.8958 - val_mae: 0.5366 - val_mse: 0.8958\n",
      "Epoch 78/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.2914 - mae: 0.3807 - mse: 0.2914 - val_loss: 0.8978 - val_mae: 0.5326 - val_mse: 0.8978\n",
      "Epoch 79/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 0.2891 - mae: 0.3784 - mse: 0.2891 - val_loss: 0.4857 - val_mae: 0.4578 - val_mse: 0.4857\n",
      "Epoch 80/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 0.2922 - mae: 0.3813 - mse: 0.2922 - val_loss: 0.4289 - val_mae: 0.4293 - val_mse: 0.4289\n",
      "Epoch 81/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 0.2886 - mae: 0.3788 - mse: 0.2886 - val_loss: 0.5488 - val_mae: 0.4427 - val_mse: 0.5488\n",
      "Epoch 82/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 0.2864 - mae: 0.3771 - mse: 0.2864 - val_loss: 0.9274 - val_mae: 0.5231 - val_mse: 0.9274\n",
      "Epoch 83/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.2895 - mae: 0.3810 - mse: 0.2895 - val_loss: 0.8115 - val_mae: 0.5121 - val_mse: 0.8115\n",
      "Epoch 84/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.2945 - mae: 0.3817 - mse: 0.2945 - val_loss: 0.9790 - val_mae: 0.5683 - val_mse: 0.9790\n",
      "Epoch 85/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.2995 - mae: 0.3844 - mse: 0.2995 - val_loss: 0.5950 - val_mae: 0.4207 - val_mse: 0.5950\n",
      "Epoch 86/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.2889 - mae: 0.3776 - mse: 0.2889 - val_loss: 0.6476 - val_mae: 0.5199 - val_mse: 0.6476\n",
      "Epoch 87/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 0.2918 - mae: 0.3815 - mse: 0.2918 - val_loss: 0.5617 - val_mae: 0.4924 - val_mse: 0.5617\n",
      "Epoch 88/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.2903 - mae: 0.3813 - mse: 0.2903 - val_loss: 0.7510 - val_mae: 0.5327 - val_mse: 0.7510\n",
      "Epoch 89/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2908 - mae: 0.3814 - mse: 0.2908 - val_loss: 0.9048 - val_mae: 0.5761 - val_mse: 0.9048\n",
      "Epoch 90/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2971 - mae: 0.3825 - mse: 0.2971 - val_loss: 0.5345 - val_mae: 0.4798 - val_mse: 0.5345\n",
      "Epoch 91/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.2912 - mae: 0.3817 - mse: 0.2912 - val_loss: 0.6753 - val_mae: 0.5486 - val_mse: 0.6753\n",
      "Epoch 92/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.2906 - mae: 0.3777 - mse: 0.2906 - val_loss: 0.5941 - val_mae: 0.5029 - val_mse: 0.5941\n",
      "Epoch 93/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.2894 - mae: 0.3789 - mse: 0.2894 - val_loss: 0.5446 - val_mae: 0.4854 - val_mse: 0.5446\n",
      "Epoch 94/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.2889 - mae: 0.3798 - mse: 0.2889 - val_loss: 0.6658 - val_mae: 0.5403 - val_mse: 0.6658\n",
      "Epoch 95/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.2879 - mae: 0.3773 - mse: 0.2879 - val_loss: 0.6534 - val_mae: 0.5074 - val_mse: 0.6534\n",
      "Epoch 96/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.2889 - mae: 0.3776 - mse: 0.2889 - val_loss: 0.6755 - val_mae: 0.4819 - val_mse: 0.6755\n",
      "Epoch 97/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.2834 - mae: 0.3747 - mse: 0.2834 - val_loss: 0.6233 - val_mae: 0.4846 - val_mse: 0.6233\n",
      "Epoch 98/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.2886 - mae: 0.3792 - mse: 0.2886 - val_loss: 0.4675 - val_mae: 0.4258 - val_mse: 0.4675\n",
      "Epoch 99/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.2935 - mae: 0.3849 - mse: 0.2935 - val_loss: 0.4861 - val_mae: 0.4654 - val_mse: 0.4861\n",
      "Epoch 100/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 0.2890 - mae: 0.3799 - mse: 0.2890 - val_loss: 0.5831 - val_mae: 0.4733 - val_mse: 0.5831\n"
     ]
    }
   ],
   "source": [
    "model_bn = keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_bn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_bn = model_bn.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b476e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 1.2766 - mae: 0.7852 - mse: 1.2687 - val_loss: 0.8826 - val_mae: 0.5300 - val_mse: 0.8747\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 0.6729 - mae: 0.5750 - mse: 0.6649 - val_loss: 0.6084 - val_mae: 0.4769 - val_mse: 0.6004\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.5908 - mae: 0.5300 - mse: 0.5827 - val_loss: 0.5308 - val_mae: 0.4676 - val_mse: 0.5227\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.5227 - mae: 0.5126 - mse: 0.5146 - val_loss: 0.4885 - val_mae: 0.4590 - val_mse: 0.4802\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.5123 - mae: 0.4951 - mse: 0.5040 - val_loss: 0.4516 - val_mae: 0.4496 - val_mse: 0.4433\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.4744 - mae: 0.4870 - mse: 0.4661 - val_loss: 0.4133 - val_mae: 0.4443 - val_mse: 0.4050\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.4639 - mae: 0.4797 - mse: 0.4555 - val_loss: 0.4046 - val_mae: 0.4417 - val_mse: 0.3962\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 0.4599 - mae: 0.4789 - mse: 0.4515 - val_loss: 0.4448 - val_mae: 0.4406 - val_mse: 0.4364\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.4646 - mae: 0.4695 - mse: 0.4562 - val_loss: 0.3929 - val_mae: 0.4393 - val_mse: 0.3845\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.4317 - mae: 0.4654 - mse: 0.4233 - val_loss: 0.3831 - val_mae: 0.4390 - val_mse: 0.3746\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 0.4250 - mae: 0.4578 - mse: 0.4165 - val_loss: 0.3811 - val_mae: 0.4293 - val_mse: 0.3726\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.4191 - mae: 0.4563 - mse: 0.4106 - val_loss: 0.3725 - val_mae: 0.4219 - val_mse: 0.3640\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.4127 - mae: 0.4520 - mse: 0.4042 - val_loss: 0.3733 - val_mae: 0.4225 - val_mse: 0.3648\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.4104 - mae: 0.4482 - mse: 0.4018 - val_loss: 0.3572 - val_mae: 0.4133 - val_mse: 0.3485\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.4049 - mae: 0.4441 - mse: 0.3962 - val_loss: 0.3493 - val_mae: 0.4129 - val_mse: 0.3405\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 0.3967 - mae: 0.4389 - mse: 0.3878 - val_loss: 0.3473 - val_mae: 0.4048 - val_mse: 0.3385\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3877 - mae: 0.4356 - mse: 0.3787 - val_loss: 0.3446 - val_mae: 0.4064 - val_mse: 0.3355\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3859 - mae: 0.4300 - mse: 0.3769 - val_loss: 0.3594 - val_mae: 0.4119 - val_mse: 0.3503\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.3854 - mae: 0.4316 - mse: 0.3763 - val_loss: 0.3460 - val_mae: 0.4080 - val_mse: 0.3369\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.3859 - mae: 0.4314 - mse: 0.3767 - val_loss: 0.3502 - val_mae: 0.4135 - val_mse: 0.3410\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3776 - mae: 0.4255 - mse: 0.3683 - val_loss: 0.3380 - val_mae: 0.3987 - val_mse: 0.3287\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3762 - mae: 0.4256 - mse: 0.3669 - val_loss: 0.3533 - val_mae: 0.4108 - val_mse: 0.3440\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3694 - mae: 0.4230 - mse: 0.3600 - val_loss: 0.3353 - val_mae: 0.3982 - val_mse: 0.3259\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3604 - mae: 0.4186 - mse: 0.3509 - val_loss: 0.3312 - val_mae: 0.3985 - val_mse: 0.3217\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3607 - mae: 0.4186 - mse: 0.3511 - val_loss: 0.3275 - val_mae: 0.3944 - val_mse: 0.3179\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.3588 - mae: 0.4174 - mse: 0.3492 - val_loss: 0.3261 - val_mae: 0.3960 - val_mse: 0.3165\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3590 - mae: 0.4186 - mse: 0.3493 - val_loss: 0.3354 - val_mae: 0.4048 - val_mse: 0.3257\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.3609 - mae: 0.4141 - mse: 0.3511 - val_loss: 0.3356 - val_mae: 0.4049 - val_mse: 0.3259\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.3581 - mae: 0.4151 - mse: 0.3483 - val_loss: 0.3318 - val_mae: 0.3986 - val_mse: 0.3219\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.3494 - mae: 0.4095 - mse: 0.3396 - val_loss: 0.3228 - val_mae: 0.3884 - val_mse: 0.3130\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.3504 - mae: 0.4112 - mse: 0.3405 - val_loss: 0.3249 - val_mae: 0.3888 - val_mse: 0.3150\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3491 - mae: 0.4099 - mse: 0.3392 - val_loss: 0.3197 - val_mae: 0.3899 - val_mse: 0.3097\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3487 - mae: 0.4111 - mse: 0.3387 - val_loss: 0.3362 - val_mae: 0.4009 - val_mse: 0.3262\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.3516 - mae: 0.4124 - mse: 0.3415 - val_loss: 0.3211 - val_mae: 0.3872 - val_mse: 0.3110\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3446 - mae: 0.4085 - mse: 0.3346 - val_loss: 0.3218 - val_mae: 0.3955 - val_mse: 0.3117\n",
      "Epoch 36/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3413 - mae: 0.4059 - mse: 0.3313 - val_loss: 0.3272 - val_mae: 0.3913 - val_mse: 0.3171\n",
      "Epoch 37/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.3434 - mae: 0.4055 - mse: 0.3333 - val_loss: 0.3230 - val_mae: 0.3918 - val_mse: 0.3130\n",
      "Epoch 38/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3453 - mae: 0.4090 - mse: 0.3352 - val_loss: 0.3191 - val_mae: 0.3920 - val_mse: 0.3090\n",
      "Epoch 39/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.3481 - mae: 0.4109 - mse: 0.3380 - val_loss: 0.3482 - val_mae: 0.3954 - val_mse: 0.3381\n",
      "Epoch 40/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3453 - mae: 0.4062 - mse: 0.3351 - val_loss: 0.3171 - val_mae: 0.3865 - val_mse: 0.3069\n",
      "Epoch 41/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3460 - mae: 0.4056 - mse: 0.3359 - val_loss: 0.3258 - val_mae: 0.3954 - val_mse: 0.3156\n",
      "Epoch 42/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3434 - mae: 0.4072 - mse: 0.3332 - val_loss: 0.3261 - val_mae: 0.4039 - val_mse: 0.3159\n",
      "Epoch 43/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.3440 - mae: 0.4085 - mse: 0.3338 - val_loss: 0.3138 - val_mae: 0.3921 - val_mse: 0.3036\n",
      "Epoch 44/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3398 - mae: 0.4046 - mse: 0.3296 - val_loss: 0.3181 - val_mae: 0.3948 - val_mse: 0.3079\n",
      "Epoch 45/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3417 - mae: 0.4063 - mse: 0.3315 - val_loss: 0.3152 - val_mae: 0.3937 - val_mse: 0.3050\n",
      "Epoch 46/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.3461 - mae: 0.4076 - mse: 0.3358 - val_loss: 0.3188 - val_mae: 0.3939 - val_mse: 0.3085\n",
      "Epoch 47/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.3463 - mae: 0.4081 - mse: 0.3361 - val_loss: 0.3153 - val_mae: 0.3901 - val_mse: 0.3050\n",
      "Epoch 48/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.3366 - mae: 0.4044 - mse: 0.3264 - val_loss: 0.3183 - val_mae: 0.3820 - val_mse: 0.3080\n",
      "Epoch 49/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3382 - mae: 0.4024 - mse: 0.3279 - val_loss: 0.3128 - val_mae: 0.3876 - val_mse: 0.3025\n",
      "Epoch 50/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.3392 - mae: 0.4050 - mse: 0.3289 - val_loss: 0.3157 - val_mae: 0.3887 - val_mse: 0.3055\n",
      "Epoch 51/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3367 - mae: 0.4030 - mse: 0.3264 - val_loss: 0.3162 - val_mae: 0.3832 - val_mse: 0.3059\n",
      "Epoch 52/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3342 - mae: 0.4016 - mse: 0.3239 - val_loss: 0.3071 - val_mae: 0.3689 - val_mse: 0.2967\n",
      "Epoch 53/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3357 - mae: 0.4007 - mse: 0.3254 - val_loss: 0.3265 - val_mae: 0.4011 - val_mse: 0.3162\n",
      "Epoch 54/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.3399 - mae: 0.4071 - mse: 0.3296 - val_loss: 0.3102 - val_mae: 0.3817 - val_mse: 0.2998\n",
      "Epoch 55/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.3364 - mae: 0.4021 - mse: 0.3259 - val_loss: 0.3280 - val_mae: 0.3801 - val_mse: 0.3176\n",
      "Epoch 56/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3567 - mae: 0.4024 - mse: 0.3463 - val_loss: 0.3090 - val_mae: 0.3797 - val_mse: 0.2986\n",
      "Epoch 57/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.3375 - mae: 0.4032 - mse: 0.3272 - val_loss: 0.3039 - val_mae: 0.3744 - val_mse: 0.2935\n",
      "Epoch 58/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.3416 - mae: 0.4051 - mse: 0.3313 - val_loss: 0.3062 - val_mae: 0.3815 - val_mse: 0.2958\n",
      "Epoch 59/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3345 - mae: 0.4026 - mse: 0.3242 - val_loss: 0.3061 - val_mae: 0.3832 - val_mse: 0.2957\n",
      "Epoch 60/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.3350 - mae: 0.4027 - mse: 0.3247 - val_loss: 0.3164 - val_mae: 0.3890 - val_mse: 0.3061\n",
      "Epoch 61/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.3341 - mae: 0.4039 - mse: 0.3237 - val_loss: 0.3050 - val_mae: 0.3846 - val_mse: 0.2947\n",
      "Epoch 62/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.3374 - mae: 0.4023 - mse: 0.3271 - val_loss: 0.3120 - val_mae: 0.3921 - val_mse: 0.3017\n",
      "Epoch 63/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3319 - mae: 0.4004 - mse: 0.3216 - val_loss: 0.3043 - val_mae: 0.3732 - val_mse: 0.2940\n",
      "Epoch 64/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3333 - mae: 0.4031 - mse: 0.3229 - val_loss: 0.3061 - val_mae: 0.3748 - val_mse: 0.2958\n",
      "Epoch 65/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3305 - mae: 0.4011 - mse: 0.3201 - val_loss: 0.3122 - val_mae: 0.3799 - val_mse: 0.3019\n",
      "Epoch 66/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3310 - mae: 0.3999 - mse: 0.3207 - val_loss: 0.3081 - val_mae: 0.3842 - val_mse: 0.2977\n",
      "Epoch 67/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3295 - mae: 0.3983 - mse: 0.3191 - val_loss: 0.3063 - val_mae: 0.3834 - val_mse: 0.2960\n",
      "Epoch 68/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.3354 - mae: 0.4038 - mse: 0.3250 - val_loss: 0.3044 - val_mae: 0.3798 - val_mse: 0.2940\n",
      "Epoch 69/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3326 - mae: 0.4003 - mse: 0.3223 - val_loss: 0.3147 - val_mae: 0.3911 - val_mse: 0.3043\n",
      "Epoch 70/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.3298 - mae: 0.3978 - mse: 0.3195 - val_loss: 0.3086 - val_mae: 0.3848 - val_mse: 0.2983\n",
      "Epoch 71/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3322 - mae: 0.4010 - mse: 0.3219 - val_loss: 0.3070 - val_mae: 0.3828 - val_mse: 0.2967\n",
      "Epoch 72/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.3358 - mae: 0.4036 - mse: 0.3255 - val_loss: 0.3054 - val_mae: 0.3817 - val_mse: 0.2951\n",
      "Epoch 73/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.3297 - mae: 0.3995 - mse: 0.3194 - val_loss: 0.3066 - val_mae: 0.3795 - val_mse: 0.2962\n",
      "Epoch 74/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.3276 - mae: 0.3967 - mse: 0.3172 - val_loss: 0.3245 - val_mae: 0.3965 - val_mse: 0.3141\n",
      "Epoch 75/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.3328 - mae: 0.4003 - mse: 0.3224 - val_loss: 0.3149 - val_mae: 0.3813 - val_mse: 0.3044\n",
      "Epoch 76/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3336 - mae: 0.4008 - mse: 0.3232 - val_loss: 0.3137 - val_mae: 0.3870 - val_mse: 0.3033\n",
      "Epoch 77/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3265 - mae: 0.3973 - mse: 0.3160 - val_loss: 0.3061 - val_mae: 0.3736 - val_mse: 0.2957\n",
      "Epoch 78/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 0.3249 - mae: 0.3975 - mse: 0.3145 - val_loss: 0.3059 - val_mae: 0.3760 - val_mse: 0.2955\n",
      "Epoch 79/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.3356 - mae: 0.4018 - mse: 0.3252 - val_loss: 0.4309 - val_mae: 0.3866 - val_mse: 0.4205\n",
      "Epoch 80/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3672 - mae: 0.4026 - mse: 0.3568 - val_loss: 0.3047 - val_mae: 0.3734 - val_mse: 0.2943\n",
      "Epoch 81/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3246 - mae: 0.3972 - mse: 0.3141 - val_loss: 0.3066 - val_mae: 0.3755 - val_mse: 0.2962\n",
      "Epoch 82/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3302 - mae: 0.3986 - mse: 0.3197 - val_loss: 0.3087 - val_mae: 0.3832 - val_mse: 0.2981\n",
      "Epoch 83/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.3295 - mae: 0.3978 - mse: 0.3190 - val_loss: 0.3225 - val_mae: 0.3844 - val_mse: 0.3119\n",
      "Epoch 84/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3273 - mae: 0.3963 - mse: 0.3168 - val_loss: 0.3100 - val_mae: 0.3917 - val_mse: 0.2995\n",
      "Epoch 85/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3389 - mae: 0.4015 - mse: 0.3284 - val_loss: 0.3085 - val_mae: 0.3782 - val_mse: 0.2980\n",
      "Epoch 86/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.3311 - mae: 0.4007 - mse: 0.3206 - val_loss: 0.3065 - val_mae: 0.3778 - val_mse: 0.2960\n",
      "Epoch 87/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 0.3335 - mae: 0.4008 - mse: 0.3230 - val_loss: 0.3031 - val_mae: 0.3788 - val_mse: 0.2926\n",
      "Epoch 88/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3270 - mae: 0.3983 - mse: 0.3164 - val_loss: 0.3055 - val_mae: 0.3749 - val_mse: 0.2950\n",
      "Epoch 89/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3304 - mae: 0.3980 - mse: 0.3199 - val_loss: 0.3071 - val_mae: 0.3809 - val_mse: 0.2965\n",
      "Epoch 90/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.3285 - mae: 0.3995 - mse: 0.3179 - val_loss: 0.3076 - val_mae: 0.3766 - val_mse: 0.2970\n",
      "Epoch 91/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.3284 - mae: 0.3968 - mse: 0.3179 - val_loss: 0.3209 - val_mae: 0.3875 - val_mse: 0.3104\n",
      "Epoch 92/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3308 - mae: 0.3995 - mse: 0.3202 - val_loss: 0.3010 - val_mae: 0.3678 - val_mse: 0.2903\n",
      "Epoch 93/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3293 - mae: 0.3975 - mse: 0.3186 - val_loss: 0.3060 - val_mae: 0.3819 - val_mse: 0.2954\n",
      "Epoch 94/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.3291 - mae: 0.3986 - mse: 0.3184 - val_loss: 0.3040 - val_mae: 0.3757 - val_mse: 0.2933\n",
      "Epoch 95/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.3328 - mae: 0.3992 - mse: 0.3221 - val_loss: 0.3003 - val_mae: 0.3676 - val_mse: 0.2896\n",
      "Epoch 96/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 0.3242 - mae: 0.3959 - mse: 0.3135 - val_loss: 0.3055 - val_mae: 0.3842 - val_mse: 0.2947\n",
      "Epoch 97/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.3270 - mae: 0.3970 - mse: 0.3163 - val_loss: 0.3085 - val_mae: 0.3760 - val_mse: 0.2977\n",
      "Epoch 98/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.3281 - mae: 0.3971 - mse: 0.3173 - val_loss: 0.3029 - val_mae: 0.3805 - val_mse: 0.2922\n",
      "Epoch 99/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3258 - mae: 0.3972 - mse: 0.3150 - val_loss: 0.3038 - val_mae: 0.3739 - val_mse: 0.2930\n",
      "Epoch 100/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 0.3254 - mae: 0.3966 - mse: 0.3147 - val_loss: 0.3012 - val_mae: 0.3736 - val_mse: 0.2905\n"
     ]
    }
   ],
   "source": [
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.3\n",
    "\n",
    "model_reg = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_reg.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg = model_reg.fit(\n",
    "    X_train_scaled, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "806165c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Model ===\n",
      "Train MAE: 0.3133, Train MSE: 0.2057\n",
      "Val   MAE: 0.3585, Val   MSE: 0.2739\n",
      "\n",
      "=== BatchNorm Model ===\n",
      "Train MAE: 0.4536, Train MSE: 0.4851\n",
      "Val   MAE: 0.4733, Val   MSE: 0.5831\n",
      "\n",
      "=== Regularized Model (L2 + Dropout) ===\n",
      "Train MAE: 0.3483, Train MSE: 0.2582\n",
      "Val   MAE: 0.3736, Val   MSE: 0.2905\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline Model ===\")\n",
    "train_scores = baseline_model.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores   = baseline_model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores[1]:.4f}, Train MSE: {train_scores[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores[1]:.4f}, Val   MSE: {val_scores[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== BatchNorm Model ===\")\n",
    "train_scores_bn = model_bn.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores_bn   = model_bn.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_bn[1]:.4f}, Train MSE: {train_scores_bn[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_bn[1]:.4f}, Val   MSE: {val_scores_bn[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "train_scores_reg = model_reg.evaluate(X_train_scaled, y_train_final, verbose=0)\n",
    "val_scores_reg   = model_reg.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg[1]:.4f}, Train MSE: {train_scores_reg[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg[1]:.4f}, Val   MSE: {val_scores_reg[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03b49813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.3630, Test MSE: 0.2794\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the test set\n",
    "test_scores = model_reg.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test MAE: {test_scores[1]:.4f}, Test MSE: {test_scores[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc2d3275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history_reg.history['loss'], label='Training Loss')\n",
    "plt.plot(history_reg.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Regularized Model Training vs. Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e912b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lab: Gaussian Mixture Models\n",
        "\n",
        "Motivation\n",
        "\n",
        "In this lab, you will apply Gaussian Mixture Models (GMM) to the Breast Cancer Wisconsin Diagnostic dataset. Unlike K-Means, GMM uses probabilistic clustering, allowing for soft assignments rather than strict cluster boundaries. This makes it useful for identifying uncertainty in clustering, such as anomalies in data.\n",
        "\n",
        "By completing the steps, you will:\n",
        "\n",
        "* Prepare and scale the dataset.\n",
        "* Determine the optimal number of clusters using BIC (Bayesian Information Criterion).\n",
        "* Perform clustering using GMM and evaluate its quality using Silhouette Score.\n",
        "* Identify potential anomalies based on cluster probabilities.\n",
        "* Compare GMM with K-Means clustering.\n",
        "\n",
        "\n",
        "This lab is auto-graded in CodeGrade, so follow the steps carefully."
      ],
      "metadata": {
        "id": "YI3SD3PxDlUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: Load and Prepare the Dataset (Provided)\n",
        "The code for this step is already given. It performs the following:\n",
        "\n",
        "* Imports necessary libraries, including GaussianMixture from sklearn.mixture.\n",
        "* Loads the Breast Cancer dataset from sklearn.datasets.load_breast_cancer().\n",
        "* Creates a DataFrame with feature data.\n",
        "* Removes labels to simulate an unsupervised learning scenario.\n",
        "\n",
        "No modifications are needed for this step."
      ],
      "metadata": {
        "id": "o9gGfAcKw-FW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HplavwJ2LdKV"
      },
      "outputs": [],
      "source": [
        "# CodeGrade step0\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_breast_cancer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step0\n",
        "\n",
        "# Load dataset\n",
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "\n",
        "# Remove labels (unsupervised learning)\n",
        "df_unlabeled = df.copy()\n"
      ],
      "metadata": {
        "id": "-P1YIAjWMKaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Rescale the Data\n",
        "Objective: Standardize the dataset before applying GMM.\n",
        "\n",
        "Instructions\n",
        "* Use StandardScaler from sklearn.preprocessing to normalize all features.\n",
        "* Fit the scaler to the dataset and transform it into a new variable called df_scaled.\n",
        "* Ensure that df_scaled retains the same shape as the original data."
      ],
      "metadata": {
        "id": "HsjY55ZMxJzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step1\n",
        "\n",
        "# Rescale\n",
        "scaler = None\n",
        "df_scaled = None\n",
        "\n",
        "# Shape\n"
      ],
      "metadata": {
        "id": "3V9L2kMfMafg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Determine the Optimal Number of Components (BIC & AIC)\n",
        "Objective: Use Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC) to find the best number of clusters.\n",
        "\n",
        "Instructions\n",
        "* Initialize two empty lists: bic_scores and aic_scores.\n",
        "* Loop over values of K from 1 to 9:\n",
        "  * Train a GaussianMixture model with k components, random_state=42, and n_init=10.\n",
        "  * Fit the model to df_scaled and store the BIC and AIC scores.\n",
        "* Compute and return the difference between the sum of BIC scores and AIC scores, rounded to 0 decimal places."
      ],
      "metadata": {
        "id": "b-zxRurmxL7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step2\n",
        "\n",
        "# ic's for k\n",
        "bic_scores = None\n",
        "aic_scores = None\n",
        "k_values = None\n",
        "\n",
        "# for loop\n",
        "\n",
        "# Round sum of difference"
      ],
      "metadata": {
        "id": "dz9JKCVdMclG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the BIC score to visualize the optimal K:\n",
        "* X-axis: Number of Components (K).\n",
        "* Y-axis: BIC Score.\n",
        "* Use markers ('o') and a line ('-')."
      ],
      "metadata": {
        "id": "EO0RsPu7EJ7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot BIC to find optimal K\n",
        "\n"
      ],
      "metadata": {
        "id": "v4yDyNp_xRYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Perform GMM Clustering\n",
        "Objective: Apply GMM clustering using the best K from Step 2.\n",
        "\n",
        "Instructions\n",
        "* Set optimal_k  (determined from BIC analysis).\n",
        "* Train a GaussianMixture model with optimal_k, random_state=42, and n_init=10.\n",
        "* Assign cluster labels to df_unlabeled[\"GMM_Cluster\"].\n",
        "* Compute and store maximum cluster probability for each sample in df_unlabeled[\"Cluster_Probability\"].\n",
        "* Compute the Silhouette Score and return it rounded to 4 decimal places."
      ],
      "metadata": {
        "id": "VrEJRq6OyzV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step3\n",
        "\n",
        "# Optimal k\n",
        "optimal_k =  None\n",
        "gmm = None\n",
        "# fit the model\n",
        "\n",
        "# Assign probabilities to each cluster\n",
        "df_unlabeled[\"GMM_Cluster\"] = None\n",
        "df_unlabeled[\"Cluster_Probability\"] = None\n",
        "\n",
        "# Find and round the Silhouette Average\n",
        "silhouette_avg = None\n",
        "# round"
      ],
      "metadata": {
        "id": "zc4V4M-vMe_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Identify Anomalies\n",
        "Objective: Detect outliers using cluster probability scores.\n",
        "\n",
        "Instructions\n",
        "* Compute the 5th percentile of df_unlabeled[\"Cluster_Probability\"].\n",
        "* Define anomalies as all data points below this threshold.\n",
        "* Return the number of anomalies detected."
      ],
      "metadata": {
        "id": "gT_RwL--zA04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step4\n",
        "\n",
        "# Anomalies\n",
        "threshold = None\n",
        "anomalies = None\n",
        "\n",
        "# Number of anomalies"
      ],
      "metadata": {
        "id": "Z0v8sAPnMh43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Compare GMM with K-Means\n",
        "Objective: Compare cluster assignments and visualize results.\n",
        "\n",
        "Instructions\n",
        "* Train a K-Means model using the same optimal_k = 2 as GMM.\n",
        "* Assign cluster labels to df_unlabeled[\"KMeans_Cluster\"].\n",
        "* Create a crosstab of GMM and K-Means cluster assignments and return its shape.\n",
        "* Apply PCA (n_components=2) to reduce dimensions.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LhWLKU8SznBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade step5\n",
        "\n",
        "# Clusering with K-means\n",
        "kmeans = None\n",
        "df_unlabeled[\"KMeans_Cluster\"] = None\n",
        "\n",
        "# Compare clustering assignments\n",
        "comparison = None # use cross.tab()\n",
        "# Return the shape of the value counts\n"
      ],
      "metadata": {
        "id": "bSL0UMSVMle4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Plot GMM clustering results in 2D:\n",
        "  * X-axis: Principal Component 1.\n",
        "  * Y-axis: Principal Component 2.\n",
        "  * Color points by GMM Cluster.\n",
        "  * Use cmap='viridis', marker 'o', and edgecolor='k'.\n",
        "* Create another plot overlaying anomalies:\n",
        "  * Mark anomalies with red 'x' symbols."
      ],
      "metadata": {
        "id": "JJ_YGPpSEkeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pca\n",
        "pca = PCA(n_components=2)\n",
        "df_pca = pca.fit_transform(df_scaled)\n",
        "\n",
        "# plot gmm\n"
      ],
      "metadata": {
        "id": "z9fXBWm9Mt0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot gmm with anomalies\n"
      ],
      "metadata": {
        "id": "8q4qPH6fMprL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}